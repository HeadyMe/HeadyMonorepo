# HEADY_BRAND:BEGIN
# HEADY SYSTEMS :: SACRED GEOMETRY
# FILE: .env.example
# LAYER: root
# 
#         _   _  _____    _  __   __
#        | | | || ____|  / \ \  / /
#        | |_| ||  _|   / _ \ \ V / 
#        |  _  || |___ / ___ \ | |  
#        |_| |_||_____/_/   \_\|_|  
# 
#    Sacred Geometry :: Organic Systems :: Breathing Interfaces
# HEADY_BRAND:END

# =============================================================================
# HEADY SYSTEMS ENVIRONMENT CONFIGURATION
# =============================================================================
# 1. Copy this file to '.env'
# 2. Replace placeholders with actual values
# 3. NEVER commit the .env file to Git (already in .gitignore)
# 4. Generate strong keys: openssl rand -base64 32
#
# For production deployment, use Render.com environment variables
# via the 'heady-shared-secrets' env group
# =============================================================================

# =============================================================================
# REQUIRED VARIABLES (System will not start without these)
# =============================================================================

# Heady API Key (Required for Admin UI and protected endpoints)
# Generate: openssl rand -base64 32
HEADY_API_KEY=your-secure-random-key-here

# Hugging Face Token (Required for AI/ML features)
# Get from: https://huggingface.co/settings/tokens
HF_TOKEN=hf_your_token_here

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================

# Server port (default: 3300)
PORT=3300

# Environment mode (development | production)
NODE_ENV=development

# =============================================================================
# HUGGING FACE MODELS
# =============================================================================

# Default text generation model
HF_TEXT_MODEL=gpt2

# Default embedding model
HF_EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Maximum concurrent Hugging Face requests
HF_MAX_CONCURRENCY=4

# =============================================================================
# PYTHON WORKER CONFIGURATION
# =============================================================================

# Python binary path (default: python)
HEADY_PYTHON_BIN=python

# Python worker timeout in milliseconds
HEADY_PY_WORKER_TIMEOUT_MS=90000

# Maximum concurrent Python workers
HEADY_PY_MAX_CONCURRENCY=2

# =============================================================================
# QA SYSTEM CONFIGURATION
# =============================================================================

# QA backend selection (auto | python | node)
HEADY_QA_BACKEND=auto

# QA model (overrides HF_TEXT_MODEL if set)
HEADY_QA_MODEL=

# Maximum new tokens for QA responses
HEADY_QA_MAX_NEW_TOKENS=256

# Maximum question length in characters
HEADY_QA_MAX_QUESTION_CHARS=4000

# Maximum context length in characters
HEADY_QA_MAX_CONTEXT_CHARS=12000

# =============================================================================
# ADMIN UI CONFIGURATION
# =============================================================================

# Admin file system root (default: repository root)
# Leave empty to use repository root
HEADY_ADMIN_ROOT=

# Additional allowed paths (comma-separated)
# Example: /home/user/projects,/opt/data
HEADY_ADMIN_ALLOWED_PATHS=

# Maximum file size for editing in bytes (default: 512000 = 512KB)
HEADY_ADMIN_MAX_BYTES=512000

# Maximum operation log entries (default: 2000)
HEADY_ADMIN_OP_LOG_LIMIT=2000

# Maximum concurrent operations (default: 50)
HEADY_ADMIN_OP_LIMIT=50

# Build script path (default: src/consolidated_builder.py)
HEADY_ADMIN_BUILD_SCRIPT=

# Audit script path (default: admin_console.py)
HEADY_ADMIN_AUDIT_SCRIPT=

# =============================================================================
# GPU CONFIGURATION (Optional - for GPU-accelerated features)
# =============================================================================

# Enable GPU features (true | false)
HEADY_ADMIN_ENABLE_GPU=false

# Remote GPU server hostname
REMOTE_GPU_HOST=

# Remote GPU server port
REMOTE_GPU_PORT=

# GPU memory limit in MB
GPU_MEMORY_LIMIT=

# Enable GPUDirect RDMA (true | false)
ENABLE_GPUDIRECT=false

# =============================================================================
# SECURITY & CORS CONFIGURATION
# =============================================================================

# Trust proxy headers (true | false) - enable in production behind proxy
HEADY_TRUST_PROXY=false

# Allowed CORS origins (comma-separated)
# Example: https://app.example.com,https://admin.example.com
HEADY_CORS_ORIGINS=

# =============================================================================
# RATE LIMITING
# =============================================================================

# Rate limit window in milliseconds (default: 60000 = 1 minute)
HEADY_RATE_LIMIT_WINDOW_MS=60000

# Maximum requests per window (default: 120)
HEADY_RATE_LIMIT_MAX=120

# =============================================================================
# OPTIONAL: EXTERNAL SERVICES
# =============================================================================

# Google Gemini API Key (for advanced AI features)
# Get from: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=

# GitHub Token (for GitHub API integration)
GH_TOKEN=

# Database URL (for database features)
# Example: postgresql://user:password@host:port/database
DATABASE_URL=

# Cloudflare API credentials (for MCP integration)
COPILOT_MCP_CLOUDFLARE_API_TOKEN=
COPILOT_MCP_CLOUDFLARE_ACCOUNT_ID=

# =============================================================================
# ADVANCED CONFIGURATION (Usually not needed)
# =============================================================================

# MCP Server timeout in milliseconds
HEADY_MCP_SERVER_TIMEOUT_MS=30000

# Maximum concurrent MCP requests
HEADY_MCP_MAX_CONCURRENT_REQUESTS=10

# Logging level (debug | info | warn | error)
HEADY_LOG_LEVEL=info

# Logging format (json | text)
HEADY_LOG_FORMAT=json

# Session secret (for future session management)
HEADY_SESSION_SECRET=

# JWT expiration time (for future JWT tokens)
HEADY_JWT_EXPIRES_IN=24h

# =============================================================================
# ENVIRONMENT-SPECIFIC EXAMPLES
# =============================================================================

# --- LOCAL DEVELOPMENT ---
# PORT=3300
# NODE_ENV=development
# HEADY_API_KEY=local-dev-key-12345
# HF_TOKEN=hf_your_dev_token
# HEADY_TRUST_PROXY=false
# HEADY_CORS_ORIGINS=http://localhost:3000,http://localhost:3300

# --- STAGING ---
# PORT=3300
# NODE_ENV=production
# HEADY_API_KEY=staging-secure-key-from-render
# HF_TOKEN=hf_staging_token
# HEADY_TRUST_PROXY=true
# HEADY_CORS_ORIGINS=https://staging.yourdomain.com

# --- PRODUCTION ---
# PORT=3300
# NODE_ENV=production
# HEADY_API_KEY=production-secure-key-from-render
# HF_TOKEN=hf_production_token
# HEADY_TRUST_PROXY=true
# HEADY_CORS_ORIGINS=https://yourdomain.com,https://admin.yourdomain.com

# =============================================================================
# SECURITY REMINDERS
# =============================================================================
# ✅ Generate strong API keys: openssl rand -base64 32
# ✅ Rotate keys quarterly in production
# ✅ Use different keys for dev/staging/production
# ✅ Never commit .env file to version control
# ✅ Use Render env groups for production secrets
# ✅ Enable HTTPS/HSTS in production
# ✅ Review and update CORS origins regularly
# =============================================================================
